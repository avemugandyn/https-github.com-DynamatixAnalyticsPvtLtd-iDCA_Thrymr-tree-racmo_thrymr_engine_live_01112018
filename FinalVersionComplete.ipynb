{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pdfquery\n",
    "import json\n",
    "from shapely.geometry import box\n",
    "from shapely.ops import cascaded_union\n",
    "import pdftableextract as pte\n",
    "from math import floor\n",
    "import pickle\n",
    "from pymongo import MongoClient\n",
    "from os import listdir\n",
    "from os.path import isfile, join, isdir\n",
    "from os.path import isfile, join, isdir\n",
    "from os import listdir\n",
    "import re\n",
    "import pickle\n",
    "import hashlib\n",
    "import unidecode\n",
    "from fuzzysearch import find_near_matches\n",
    "import textract\n",
    "import unicodedata\n",
    "class dbConf(object):\n",
    "    # connect to database\n",
    "    client = MongoClient('mongodb://localhost:27017/')\n",
    "    try:\n",
    "        mdb = client.racmo\n",
    "        Notifications = mdb.Notifications\n",
    "        PdfFiles=mdb.PdfFiles\n",
    "        Keywords=mdb.Keywords\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "PDF_DIR = \"/home/thrymr/Racmo/processed/Final version of Notifications/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "KeywordDir=\"/home/thrymr/Racmo/Notification Keywords/\"\n",
    "keyword_files = [join(KeywordDir,f) for f in listdir(KeywordDir)\\\n",
    "                 if isfile(join(KeywordDir, f)) and \n",
    "                 f[-4:].lower() == \"xlsx\"]\n",
    "ls=[]\n",
    "\n",
    "for f in keyword_files:\n",
    "    xl_file = pd.ExcelFile(f)\n",
    "    dfs = xl_file.parse(xl_file.sheet_names[0])\n",
    "\n",
    "    tic=False\n",
    "    for index, row in dfs.iterrows():\n",
    "        ite=dict()\n",
    "        if(row[0]=='TICKETS' or row[0]=='TICKET'):\n",
    "            tic=True\n",
    "        if(row[0]!='TICKETS' and row[0]!='TICKET' and isinstance(row[0], basestring)):\n",
    "\n",
    "            ite['file_class']=f.split('/')[-1].split()[0]\n",
    "            ite['notification_type']=row[0]\n",
    "            if(tic):\n",
    "                ite['file_type']='TICKET'\n",
    "            else:\n",
    "                ite['file_type']='NOTIFICATION'\n",
    "            kw=list()\n",
    "            for i in range(1,row.size):\n",
    "                if(isinstance(row[i], basestring) and row[i]!='+'):\n",
    "                    kw.append(unidecode.unidecode(row[i]).lower() )\n",
    "            ite['keyword']=kw        \n",
    "            ls.append(ite)\n",
    "newkdf=pd.DataFrame(ls)\n",
    "# newkdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.pickle', 'rb') as handle:\n",
    "    b = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kdf=b['keywords']\n",
    "kdf=newkdf\n",
    "fdf=b['documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('train2.pickle', 'rb') as handle:\n",
    "#     b = pickle.load(handle)\n",
    "#     df=b['documents']\n",
    "    \n",
    "# fdf['table_response']=df['table_response']\n",
    "# fdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfclass={'N1':'ADMISSION','N2':'TRANSFER OF LEGAL REPRESENTATION PERMITTED',\n",
    "           'N3':'ENFORCEMENT ORDERS','N4':'STATEMENT OF PAYMENT',\n",
    "           'N5':'REJECTED CLAIMS','N6':'REJECTED TRANSFER OF LEGAL REPRESENTATION',\n",
    "           'N7':'HEARING','N8':'ASSET INQUIRY',\n",
    "           'N9':'PLACE OF RESIDENCY REQUIRED',\n",
    "           'N10':'REQUIREMENT'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdf['purpose']=''\n",
    "n=kdf.iterrows()\n",
    "for i,row in n:\n",
    "    if 'EJECUCION DE TITULOS NO JUDICIALES'.lower() in row['keyword']:\n",
    "        kdf=kdf.drop(kdf.index[i])\n",
    "    elif(not ( row['file_class'] =='N5'or row['file_class'] =='N6')):\n",
    "        if(pdfclass[row['file_class']] in row['notification_type']):\n",
    "            \n",
    "            kdf.loc[i,'purpose']='CLASSIFICATION'\n",
    "        else:\n",
    "            kdf.loc[i,'purpose']='EXTRACTION'\n",
    "    elif row['file_class'] =='N5':\n",
    "        if('N5 - REJECTED CLAIMS' in row['notification_type']):\n",
    "            kdf.loc[i,'purpose']='CLASSIFICATION'\n",
    "        else:\n",
    "            kdf.loc[i,'purpose']='EXTRACTION'\n",
    "    elif row['file_class'] =='N6':\n",
    "        if('N6 - REJECTED TRANSFER OF LEGAL REPRESENTATION' in row['notification_type']):\n",
    "            kdf.loc[i,'purpose']='CLASSIFICATION'\n",
    "        else:\n",
    "            kdf.loc[i,'purpose']='EXTRACTION'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k=kdf[(kdf['file_class']=='N10') & (kdf['purpose']=='CLASSIFICATION')&(kdf['file_type']=='NOTIFICATION')].groupby('notification_type')\n",
    "# print(k.groups)\n",
    "# new10df=pd.DataFrame(columns=kdf.columns)\n",
    "# i=0\n",
    "# for lidx in k.groups['N10 - REQUIREMENTS']:\n",
    "#     for ridx in k.groups['N10 -  REQUIREMENT SPECIFICATION']:\n",
    "#         new10df=new10df.append(kdf.iloc[lidx],ignore_index=True)\n",
    "        \n",
    "#         new10df.loc[i,'keyword']=new10df.loc[i,'keyword']+kdf.loc[ridx,'keyword']\n",
    "#         i=i+1\n",
    "\n",
    "# new10df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fdf=b['documents']\n",
    "# fdf['fileclass']=fdf['fileclass'].apply(lambda x :x.split()[0])\n",
    "# fdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdf=kdf[~((kdf['file_class']=='N10') & (kdf['purpose']=='CLASSIFICATION')&(kdf['file_type']=='NOTIFICATION'))].append(new10df,ignore_index=True)\n",
    "# kdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdf=kdf.rename(columns={'file_class':'fileclass','file_type':'filetype'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,r in fdf.iterrows():\n",
    "    try:\n",
    "        newtext =unicode(textract.process(join(PDF_DIR,r['filename'])),'utf-8')\n",
    "        newtext=(''.join((c for c in unicodedata.normalize('NFD', newtext) if unicodedata.category(c) != 'Mn'))).lower()\n",
    "        rem=''\n",
    "        paratlist=['MODO DE IMPUGNACION:'.lower(),'mode d\\'impugnacio','recurso de repelacion','recurs de reposicio','recurso de reposicion','recurso de apelacion']\n",
    "        if (r['filetype']=='NOTIFICATION') :\n",
    "            for parat in paratlist:\n",
    "                if (parat.lower() in newtext) :\n",
    "                    rem=re.split(r'\\s(?=(?:y firmo|y firma))',newtext.split(parat.lower())[-1],1)[0]\n",
    "            newtext=newtext.replace(rem,'')\n",
    "    except Exception as e:\n",
    "        newtext='Error:'+str(e)\n",
    "    fdf.loc[i,'text_response']=newtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# kdf[\"document_list\"]=np.empty((len(kdf), 0)).tolist()\n",
    "# fdf[\"keywords\"]=fdf[\"hasid\"].apply(lambda x:{})\n",
    "\n",
    "# notextset=set()\n",
    "# for i,kdrow in kdf.iterrows():\n",
    "#     for j,row in fdf.iterrows():\n",
    "#         text=''.join(row['text_response'].split())\n",
    "# #         \n",
    "#         if row['text_response'][:5]!='Error':\n",
    "            \n",
    "#             f=True\n",
    "#             for k in kdrow['keyword']:\n",
    "# #                 if not re.search(k, row['text_response'], re.IGNORECASE):\n",
    "                \n",
    "# #                 print(unidecode.unidecode(k).lower(),find_near_matches(unidecode.unidecode(k).lower(), text, max_l_dist=1))\n",
    "# #                 match=[]\n",
    "# #                 try:\n",
    "# #                     match=find_near_matches(str(unidecode.unidecode(k)).lower(), text, max_l_dist=2)\n",
    "# #                 except Exception as e:\n",
    "# #                     notextset.add(j)\n",
    "# #                 if len(match)==0:\n",
    "# #                     f=False\n",
    "#                 if not (''.join(unidecode.unidecode(unicode(k,'utf-8')).split()).lower() in text):\n",
    "#                     f=False\n",
    "#             if f and (kdrow['filetype']==row['filetype'])and (kdrow['purpose']=='CLASSIFICATION'):\n",
    "#                 kdf.loc[i,\"document_list\"].append(row['hasid'])\n",
    "                \n",
    "#                 if kdrow['fileclass'] in fdf.loc[j,'keywords'].keys():\n",
    "#                     fdf.loc[j,'keywords'][kdrow['fileclass']].append(kdrow['keyword'])\n",
    "#                 else:\n",
    "#                     fdf.loc[j,'keywords'][kdrow['fileclass']]=list()\n",
    "#                     fdf.loc[j,'keywords'][kdrow['fileclass']].append(kdrow['keyword'])\n",
    "# fdf\n",
    "# # for idf,rowdf in fdf.iterrows():\n",
    "# #     keywords=[]\n",
    "# #     keywordclass=[]\n",
    "    \n",
    "# #     for ki, kr in kddf.iterrows():\n",
    "# #         if rowdf['hasid'] in kr['document_list'] :\n",
    "# #             if kr['file_class'] in fdf.columns:\n",
    "# #                 dokydf.loc[idf,kr['file_class']]+=1\n",
    "# #             else:\n",
    "# #                 dokydf[kr['file_class']]=0\n",
    "# #                 dokydf.loc[idf,kr['file_class']]=1\n",
    "# # .to_csv(\"keywords.csv\")  \n",
    "# # keyrpo=pd.concat([keyrpo.drop(['key_count'], axis=1), keyrpo['key_count'].apply(pd.Series)], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fdf['fileclass']=fdf['filename'].apply(lambda x : x.split()[0])\n",
    "# kdf.to_csv('dist2_keyword_train.csv')\n",
    "a = {'documents':fdf,'keywords':kdf}\n",
    "with open('Modified_train.pickle', 'wb') as handle:\n",
    "    pickle.dump(a, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fileclass</th>\n",
       "      <th>filetype</th>\n",
       "      <th>keyword</th>\n",
       "      <th>notification_type</th>\n",
       "      <th>purpose</th>\n",
       "      <th>document_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>N1</td>\n",
       "      <td>TICKET</td>\n",
       "      <td>[notifica admisa'n y requerimiento de pago]</td>\n",
       "      <td>N1 - ADMISSION</td>\n",
       "      <td>CLASSIFICATION</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>N1</td>\n",
       "      <td>TICKET</td>\n",
       "      <td>[noti. admissia requeriment de pagament]</td>\n",
       "      <td>N1 - ADMISSION</td>\n",
       "      <td>CLASSIFICATION</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fileclass filetype                                      keyword  \\\n",
       "41        N1   TICKET  [notifica admisa'n y requerimiento de pago]   \n",
       "42        N1   TICKET     [noti. admissia requeriment de pagament]   \n",
       "\n",
       "   notification_type         purpose document_list  \n",
       "41    N1 - ADMISSION  CLASSIFICATION            []  \n",
       "42    N1 - ADMISSION  CLASSIFICATION            []  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import textract\n",
    "\n",
    "_kdf = kdf[kdf.document_list.apply(lambda x : len(x) == 0)]\n",
    "_kdf[(kdf['fileclass']=='N1')&(kdf['purpose']=='CLASSIFICATION')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('Modified_train.pickle', 'rb') as handle:\n",
    "    b=pickle.load(handle)\n",
    "kdf=b['keywords']\n",
    "fdf=b['documents']   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dokydf=fdf.copy()[['filename','filetype','keywords']]\n",
    "keyrpodf=kdf.copy()\n",
    "for idf,rowdf in fdf.iterrows():\n",
    "    keywords=[]\n",
    "    keywordclass=[]\n",
    "    for k,v in rowdf['keywords'].items():\n",
    "        if 'key '+k in dokydf.columns:\n",
    "                dokydf.loc[idf,'key '+k].append(v)\n",
    "        else:\n",
    "                dokydf['key '+k]=np.empty((len(dokydf), 0)).tolist()\n",
    "                dokydf.loc[idf,'key '+k].append(v)\n",
    "    for ki, kr in kdf.iterrows():\n",
    "            if rowdf['hasid'] in kr['document_list'] :\n",
    "                if kr['fileclass'] in dokydf.columns:\n",
    "                    dokydf.loc[idf,kr['fileclass']]+=1\n",
    "                else:\n",
    "                    dokydf[kr['fileclass']]=0\n",
    "                    dokydf.loc[idf,kr['fileclass']]=1\n",
    "                if 'Filename '+ rowdf['fileclass'] in keyrpodf.columns:\n",
    "                    keyrpodf.loc[ki,'Filename '+ rowdf['fileclass']].append(rowdf['filename'])\n",
    "                else:\n",
    "                    keyrpodf['Filename '+ rowdf['fileclass']]=np.empty((len(keyrpodf), 0)).tolist()\n",
    "                    keyrpodf.loc[ki,'Filename '+ rowdf['fileclass']].append(rowdf['filename'])\n",
    "        \n",
    "\n",
    "# .to_csv(\"keywords.csv\")  \n",
    "# keyrpo=pd.concat([keyrpo.drop(['key_count'], axis=1), keyrpo['key_count'].apply(pd.Series)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('/home/thrymr/fuzzy2/keywordDetails.xlsx')\n",
    "keyrpodf.to_excel(writer,'Sheet1')\n",
    "writer.save()\n",
    "writer = pd.ExcelWriter('/home/thrymr/fuzzy2/FileDetails.xlsx')\n",
    "dokydf.to_excel(writer,'Sheet1')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "kxddf=keyrpodf.copy()[['fileclass','filetype','purpose','notification_type','keyword','document_list']]\n",
    "col=[x.split()[-1] for x in keyrpodf.columns[-10:] ]\n",
    "for i,r in keyrpodf.iterrows():\n",
    "    for c in col:\n",
    "        kxddf.loc[i,c]=len(keyrpodf.loc[i,'Filename '+c])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,row in kxddf.iterrows():\n",
    "    biased=''\n",
    "    keyscore=dict(row[-10:])\n",
    "    biased=max(keyscore, key=keyscore.get)\n",
    "    if keyscore[biased]>0:\n",
    "        kxddf.loc[i,'bias']=biased\n",
    "    else:\n",
    "        kxddf.loc[i,'bias']=row['fileclass']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = {'keywordsX':kxddf[['fileclass','filetype','purpose','notification_type','keyword','bias']]}\n",
    "with open('Final_Keyword_Analysis.pickle', 'wb') as handle:\n",
    "    pickle.dump(a, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "a = {'keywordsX':kxddf}\n",
    "with open('Keyword_Analysis.pickle', 'wb') as handle:\n",
    "    pickle.dump(a, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actu=pd.Series(list(ddf['fileclass']), name='Actual')\n",
    "\n",
    "y_pred = pd.Series(list(ddf['predicted_class']), name='Predicted')\n",
    "y_pred=y_pred.apply(lambda x:'_alpha' if x!=x else x)\n",
    "df_confusion = pd.crosstab(y_actu, y_pred,margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>N1</th>\n",
       "      <th>N10</th>\n",
       "      <th>N2</th>\n",
       "      <th>N2+N4</th>\n",
       "      <th>N3</th>\n",
       "      <th>N4</th>\n",
       "      <th>N5</th>\n",
       "      <th>N6</th>\n",
       "      <th>N7</th>\n",
       "      <th>N8</th>\n",
       "      <th>N9</th>\n",
       "      <th>_alpha</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>N1</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N10</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>13</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>41</td>\n",
       "      <td>26</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>50</td>\n",
       "      <td>38</td>\n",
       "      <td>30</td>\n",
       "      <td>46</td>\n",
       "      <td>29</td>\n",
       "      <td>43</td>\n",
       "      <td>157</td>\n",
       "      <td>552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  N1  N10  N2  N2+N4  N3  N4  N5  N6  N7  N8  N9  _alpha  All\n",
       "Actual                                                                \n",
       "N1         41    0   0      0   4   0   0   0   0   0   1       7   53\n",
       "N10         0   24   1      0   0   0   2   2   0   0   0      29   58\n",
       "N2          0    0  40      2   0   0   0   0   0   0   0      16   58\n",
       "N3          0    0   0      0  44   0   0   0   0   0   0      13   57\n",
       "N4          0    0   0      0   0  50   0   0   0   0   0       8   58\n",
       "N5          0    1   0      0   0   0  35   1   0   0   0      22   59\n",
       "N6          0    0   1      0   0   0   1  27   0   0   0      29   58\n",
       "N7          0    0   0      0   0   0   0   0  46   0   0      10   56\n",
       "N8          0    0   0      0   0   0   0   0   0  29   0      10   39\n",
       "N9          0    1   0      0   0   0   0   0   0   0  42      13   56\n",
       "All        41   26  42      2  48  50  38  30  46  29  43     157  552"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_confusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgs=ddf.groupby('filegroup')\n",
    "len(fgs.groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgdf=pd.DataFrame(columns=['filegroup','filegroupclass'])\n",
    "i=0\n",
    "fgdf['files']=np.empty((293, 0)).tolist()\n",
    "fgdf['filetypes']=np.empty((293, 0)).tolist()\n",
    "fgdf['predicted_classes']=np.empty((293, 0)).tolist()\n",
    "for k,v in fgs.groups.items():\n",
    "    \n",
    "    fgdf.loc[i,'filegroup']=k\n",
    "    fgdf.loc[i,'filegroupclass']=ddf.loc[v[0],'fileclass']\n",
    "    files=[]\n",
    "    pcs=[]\n",
    "    filetypes=[]\n",
    "    for ind in v:\n",
    "            files.append(ddf.loc[ind,'filename'])\n",
    "            pcs.append(ddf.loc[ind,'predicted_class'])\n",
    "            filetypes.append(ddf.loc[ind,'filetype'])\n",
    "    fgdf.loc[i,'filetypes']=filetypes\n",
    "    fgdf.loc[i,'files']=files\n",
    "    fgdf.loc[i,'predicted_classes']=pcs\n",
    "    i+=1\n",
    "fgdf          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actufg=[]\n",
    "y_predfg=[]\n",
    "conflic=[]\n",
    "for k,v in fgs.groups.items():\n",
    "    y_actufg.append(ddf.loc[v[0],'fileclass'])\n",
    "    s=set()\n",
    "    e='_alpha'\n",
    "    for i in v:\n",
    "        s.add(ddf.loc[i,'predicted_class'])\n",
    "#     s={x for x in s if x==x}\n",
    "    if(len(s)==1):\n",
    "        if list(s)[0]==list(s)[0]:\n",
    "            e=list(s)[0]\n",
    "            y_predfg.append(list(s)[0])\n",
    "    else:\n",
    "        \n",
    "        if(len({x for x in s if x==x})>1):\n",
    "            e='Conflict'\n",
    "             \n",
    "        else:\n",
    "            \n",
    "            for x in list(s):\n",
    "                if x==x:\n",
    "                    e=x\n",
    "    if e!='_alpha' and e!='Conflict':\n",
    "        fgdf.loc[(fgdf['filegroup'] == k),'group_predicted_class']=e\n",
    "    elif e=='Conflict':\n",
    "        for j in v:\n",
    "            if ddf.loc[j,'filetype']=='TICKET':\n",
    "                e=ddf.loc[j,'predicted_class']\n",
    "                fgdf.loc[(fgdf['filegroup'] == k),'group_predicted_class']=e\n",
    "    y_predfg.append(e)        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filegroup</th>\n",
       "      <th>filegroupclass</th>\n",
       "      <th>files</th>\n",
       "      <th>filetypes</th>\n",
       "      <th>predicted_classes</th>\n",
       "      <th>group_predicted_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>01INADMITIDASUCESIONPROCESAL</td>\n",
       "      <td>N6</td>\n",
       "      <td>[N6 REJECTED TRANSFER OF LEGAL REPRESENTATION/...</td>\n",
       "      <td>[TICKET, NOTIFICATION]</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29INADMITIDASUCESIONPROCESAL</td>\n",
       "      <td>N6</td>\n",
       "      <td>[N6 REJECTED TRANSFER OF LEGAL REPRESENTATION/...</td>\n",
       "      <td>[NOTIFICATION]</td>\n",
       "      <td>[nan]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>20INADMITIDASUCESIONPROCESAL</td>\n",
       "      <td>N6</td>\n",
       "      <td>[N6 REJECTED TRANSFER OF LEGAL REPRESENTATION/...</td>\n",
       "      <td>[NOTIFICATION, TICKET]</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>12INADMITIDASUCESIONPROCESAL</td>\n",
       "      <td>N6</td>\n",
       "      <td>[N6 REJECTED TRANSFER OF LEGAL REPRESENTATION/...</td>\n",
       "      <td>[TICKET, NOTIFICATION]</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>18INADMITIDASUCESIONPROCESAL</td>\n",
       "      <td>N6</td>\n",
       "      <td>[N6 REJECTED TRANSFER OF LEGAL REPRESENTATION/...</td>\n",
       "      <td>[TICKET, NOTIFICATION]</td>\n",
       "      <td>[nan, N5]</td>\n",
       "      <td>N5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>08INADMITIDASUCESIONPROCESAL</td>\n",
       "      <td>N6</td>\n",
       "      <td>[N6 REJECTED TRANSFER OF LEGAL REPRESENTATION/...</td>\n",
       "      <td>[TICKET, NOTIFICATION]</td>\n",
       "      <td>[N2, nan]</td>\n",
       "      <td>N2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>21INADMITIDASUCESIONPROCESAL</td>\n",
       "      <td>N6</td>\n",
       "      <td>[N6 REJECTED TRANSFER OF LEGAL REPRESENTATION/...</td>\n",
       "      <td>[TICKET, NOTIFICATION]</td>\n",
       "      <td>[nan, nan]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        filegroup filegroupclass  \\\n",
       "16   01INADMITIDASUCESIONPROCESAL             N6   \n",
       "29   29INADMITIDASUCESIONPROCESAL             N6   \n",
       "65   20INADMITIDASUCESIONPROCESAL             N6   \n",
       "113  12INADMITIDASUCESIONPROCESAL             N6   \n",
       "125  18INADMITIDASUCESIONPROCESAL             N6   \n",
       "253  08INADMITIDASUCESIONPROCESAL             N6   \n",
       "278  21INADMITIDASUCESIONPROCESAL             N6   \n",
       "\n",
       "                                                 files  \\\n",
       "16   [N6 REJECTED TRANSFER OF LEGAL REPRESENTATION/...   \n",
       "29   [N6 REJECTED TRANSFER OF LEGAL REPRESENTATION/...   \n",
       "65   [N6 REJECTED TRANSFER OF LEGAL REPRESENTATION/...   \n",
       "113  [N6 REJECTED TRANSFER OF LEGAL REPRESENTATION/...   \n",
       "125  [N6 REJECTED TRANSFER OF LEGAL REPRESENTATION/...   \n",
       "253  [N6 REJECTED TRANSFER OF LEGAL REPRESENTATION/...   \n",
       "278  [N6 REJECTED TRANSFER OF LEGAL REPRESENTATION/...   \n",
       "\n",
       "                  filetypes predicted_classes group_predicted_class  \n",
       "16   [TICKET, NOTIFICATION]        [nan, nan]                   NaN  \n",
       "29           [NOTIFICATION]             [nan]                   NaN  \n",
       "65   [NOTIFICATION, TICKET]        [nan, nan]                   NaN  \n",
       "113  [TICKET, NOTIFICATION]        [nan, nan]                   NaN  \n",
       "125  [TICKET, NOTIFICATION]         [nan, N5]                    N5  \n",
       "253  [TICKET, NOTIFICATION]         [N2, nan]                    N2  \n",
       "278  [TICKET, NOTIFICATION]        [nan, nan]                   NaN  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fgdf[~(fgdf['filegroupclass']==fgdf['group_predicted_class'])&(fgdf['filegroupclass']=='N6')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'documents':fdf,'keywords':kdf,'filegroup':fgdf}\n",
    "with open('Modified_train1.pickle', 'wb') as handle:\n",
    "    pickle.dump(a, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>N1</th>\n",
       "      <th>N10</th>\n",
       "      <th>N2</th>\n",
       "      <th>N2+N4</th>\n",
       "      <th>N3</th>\n",
       "      <th>N4</th>\n",
       "      <th>N5</th>\n",
       "      <th>N6</th>\n",
       "      <th>N7</th>\n",
       "      <th>N8</th>\n",
       "      <th>N9</th>\n",
       "      <th>_alpha</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>N1</th>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N10</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>29</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "      <td>26</td>\n",
       "      <td>29</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  N1  N10  N2  N2+N4  N3  N4  N5  N6  N7  N8  N9  _alpha  All\n",
       "Actual                                                                \n",
       "N1         29    0   0      0   0   0   0   0   0   0   1       0   30\n",
       "N10         0   19   1      0   0   0   2   2   0   0   0       6   30\n",
       "N2          0    0  28      2   0   0   0   0   0   0   0       0   30\n",
       "N3          0    0   0      0  29   0   0   0   0   0   0       2   31\n",
       "N4          0    0   0      0   0  27   0   0   0   0   0       5   32\n",
       "N5          0    1   0      0   0   0  28   1   0   0   0       0   30\n",
       "N6          0    0   1      0   0   0   1  23   0   0   0       5   30\n",
       "N7          0    0   0      0   0   0   0   0  29   0   0       1   30\n",
       "N8          0    0   0      0   0   0   0   0   0  20   0       0   20\n",
       "N9          0    0   0      0   0   0   0   0   0   0  29       1   30\n",
       "All        29   20  30      2  29  27  31  26  29  20  30      20  293"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_confusionfg = pd.crosstab(pd.Series(list(fgdf['filegroupclass']),name='Actual'), pd.Series(list(fgdf['group_predicted_class'].fillna('_alpha')),name='Predicted'),margins=True)\n",
    "df_confusionfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "order=['fileclass','filetype','purpose','keyword','N1','N2','N3','N4','N5','N6','N7','N8','N9','N10','bias']\n",
    "\n",
    "kxddf=kxddf[order]\n",
    "kxddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>N1</th>\n",
       "      <th>N2</th>\n",
       "      <th>N3</th>\n",
       "      <th>N4</th>\n",
       "      <th>N5</th>\n",
       "      <th>N6</th>\n",
       "      <th>N7</th>\n",
       "      <th>N8</th>\n",
       "      <th>N9</th>\n",
       "      <th>N10</th>\n",
       "      <th>_alpha</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>N1</th>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_alpha</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>29.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>293.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    N1    N2    N3    N4    N5    N6    N7    N8    N9   N10  _alpha  \\\n",
       "Actual                                                                          \n",
       "N1         29.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   1.0   0.0     0.0   \n",
       "N2          0.0  28.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0     0.0   \n",
       "N3          0.0   0.0  29.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0     2.0   \n",
       "N4          0.0   0.0   0.0  27.0   0.0   0.0   0.0   0.0   0.0   0.0     5.0   \n",
       "N5          0.0   0.0   0.0   0.0  28.0   1.0   0.0   0.0   0.0   1.0     0.0   \n",
       "N6          0.0   1.0   0.0   0.0   1.0  23.0   0.0   0.0   0.0   0.0     5.0   \n",
       "N7          0.0   0.0   0.0   0.0   0.0   0.0  29.0   0.0   0.0   0.0     1.0   \n",
       "N8          0.0   0.0   0.0   0.0   0.0   0.0   0.0  20.0   0.0   0.0     0.0   \n",
       "N9          0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  29.0   0.0     1.0   \n",
       "N10         0.0   1.0   0.0   0.0   2.0   2.0   0.0   0.0   0.0  19.0     6.0   \n",
       "_alpha      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0     0.0   \n",
       "All        29.0  30.0  29.0  27.0  31.0  26.0  29.0  20.0  30.0  20.0    20.0   \n",
       "\n",
       "Predicted    All  \n",
       "Actual            \n",
       "N1          30.0  \n",
       "N2          30.0  \n",
       "N3          31.0  \n",
       "N4          32.0  \n",
       "N5          30.0  \n",
       "N6          30.0  \n",
       "N7          30.0  \n",
       "N8          20.0  \n",
       "N9          30.0  \n",
       "N10         30.0  \n",
       "_alpha       0.0  \n",
       "All        293.0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order=['N1','N2','N3','N4','N5','N6','N7','N8','N9','N10','_alpha','All']\n",
    "df_confusionfg=df_confusionfg.reindex(order)\n",
    "df_confusionfg=df_confusionfg[order].fillna(0)\n",
    "df_confusionfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filegroup</th>\n",
       "      <th>filegroupclass</th>\n",
       "      <th>files</th>\n",
       "      <th>filetypes</th>\n",
       "      <th>predicted_classes</th>\n",
       "      <th>group_predicted_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [filegroup, filegroupclass, files, filetypes, predicted_classes, group_predicted_class]\n",
       "Index: []"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch=pd.DataFrame(columns=fgdf.columns)\n",
    "for i,r in fgdf.iterrows():\n",
    "    if (not (r['filegroupclass'] in r['predicted_classes'])) and  (r['group_predicted_class']==\"Conflict\"):\n",
    "        \n",
    "        ch=ch.append(r)\n",
    "ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('/home/thrymr/fuzzy2/Keyword_Analysis.xlsx')\n",
    "kxddf.to_excel(writer,'Sheet1')\n",
    "writer.save()\n",
    "writer = pd.ExcelWriter('/home/thrymr/fuzzy2/File_Classification_Analysis(AllFiles).xlsx')\n",
    "ddf.to_excel(writer,'Sheet1')\n",
    "writer.save()\n",
    "writer = pd.ExcelWriter('/home/thrymr/fuzzy2/ConfusionMatrix(All_Files).xlsx')\n",
    "df_confusion.to_excel(writer,'Sheet1')\n",
    "writer.save()\n",
    "writer = pd.ExcelWriter('/home/thrymr/fuzzy2/File_Group_Classification_Analysis.xlsx')\n",
    "fgdf.to_excel(writer,'Sheet1')\n",
    "writer.save()\n",
    "writer = pd.ExcelWriter('/home/thrymr/fuzzy2/ConfusionMatrix(FileGroup).xlsx')\n",
    "df_confusionfg.to_excel(writer,'Sheet1')\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('Modified_train1.pickle', 'rb') as handle:\n",
    "    a=pickle.load(handle)\n",
    "fgdf=a['filegroup']\n",
    "fdf=a['documents']\n",
    "kdf=a['keywords']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kdf[kdf['fileclass']=='N5']\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "key=kdf[kdf['fileclass']=='N5'].loc[122]['keyword']\n",
    "# fdf[(fdf['filename'].str.contains('/01 ')) &(fdf['fileclass']=='N6')&(fdf['filetype']=='NOTIFICATION')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "procedures={'CAM':'Cambiario','COG':'Cognicion','CON':'Concurso Acreedores','EJE':'Juicio Ejecutivo','ETJ':'EJECUCION DE TITULOS JUDICIAL','ETJH':'ETJ Continuacion Hipotecario','ETN':'EJECUCION DE TITULOS NO JUDICIAL',\\\n",
    "            'HIP':'EJECUCION Hipotecaria','MCU':'Menor Cuantia','MON':'Monitorio','ORD':'Ordinario','TDO':'Terceria De Domino','TMD':'Terceria De Mejor Derecho','VER':'Verbal','PEN':'Penal','RAP':'Recurso De Apelacion',\\\n",
    "            'PTC':'Pieza Tasacion Costas','PSO':'Pieza Seperada Oposicion','AUX':'Auxilio Nacional','CNJ':'Cosignacion Judicial','RCS':'Recurso De Casacion','INC':'Incidente Concursal','MC':'Medidas Cautelares','CN':'Conciliacion'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "extKeywords=kdf[kdf['purpose']=='EXTRACTION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "extKeywords['notification_type']=extKeywords['notification_type'].apply(lambda x : x.split('-')[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u' AMOUNT',\n",
       " u' DATE/TIME',\n",
       " u' NEGATIVE RESULT OF SEARCH',\n",
       " u' RACMO REASON FOR REJECTION',\n",
       " u' TIME FRAME',\n",
       " u' UNSPECIFIED REJECTED TRANSFER OF LEGAL REPRESENTATION',\n",
       " u'RACMO REASON REJECTED CLAIMS '}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(extKeywords['notification_type'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extKeywords[extKeywords['notification_type'].str.contains('TIME FRAME')]\n",
    "# extKeywords[extKeywords['fileclass']=='N6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>filetype</th>\n",
       "      <th>hasid</th>\n",
       "      <th>table_response</th>\n",
       "      <th>text_response</th>\n",
       "      <th>fileclass</th>\n",
       "      <th>filegroup</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N5 REJECTED CLAIMS/INADMISION 18-JUST.pdf</td>\n",
       "      <td>TICKET</td>\n",
       "      <td>353448baec4bed856f04cb31a1573bc0e44b8d34b26b92...</td>\n",
       "      <td>{\"table_1\": {\"Destinatarios\": {\"_value\": \"ALCO...</td>\n",
       "      <td>mensaje lexnet - notificacion\\nmensaje\\nidlexn...</td>\n",
       "      <td>N5</td>\n",
       "      <td>INADMISION18</td>\n",
       "      <td>{u'N5': [[u'auto inadmision contrato ilegible']]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    filename filetype  \\\n",
       "0  N5 REJECTED CLAIMS/INADMISION 18-JUST.pdf   TICKET   \n",
       "\n",
       "                                               hasid  \\\n",
       "0  353448baec4bed856f04cb31a1573bc0e44b8d34b26b92...   \n",
       "\n",
       "                                      table_response  \\\n",
       "0  {\"table_1\": {\"Destinatarios\": {\"_value\": \"ALCO...   \n",
       "\n",
       "                                       text_response fileclass     filegroup  \\\n",
       "0  mensaje lexnet - notificacion\\nmensaje\\nidlexn...        N5  INADMISION18   \n",
       "\n",
       "                                            keywords  \n",
       "0  {u'N5': [[u'auto inadmision contrato ilegible']]}  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdf[fdf['filename'].isin(['N5 REJECTED CLAIMS/INADMISION 18-JUST.pdf'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "numspan={\"1\":\"uno\",\"2\":\"dos\",\"3\":\"tres\",\"4\":\"cuatro\",\"5\":\"cinco\",\"6\":\"seis\",\"7\":\"siete\",\"8\":\"ocho\",\"9\":\"nueve\",\"10\":\"diez\",\"11\":\"once\",\"12\":\"doce\",\"13\":\"trece\",\"14\":\"catorce\",\"15\":\"quince\",\"16\":\"dieciseis\",\"17\" :\"diecisiete\",\"18\":\"dieciocho\",\"19\":\"diecinueve\",\"20\" : \"veinte\",\"21\" : \"veintiuno\",\"22\"  :\"veintids\",\"23\" : \"veintitrs\",\"24\" : \"veinticuatro\",\"25\" : \"veinticinco\",\"26\":\"veintisis\",\"27\" :\"veintisiete\",\"28\": \"veintiocho\",\"29\"  :\"veintinueve\",\"30\" : \"treinta\"}\n",
    "numcat={\"1\":\"un\",\"2\":\"dos\",\"3\":\"tres\",\"4\":\"quatre\",\"5\":\"cinc\",\"6\":\"sis\",\"7\":\"set\",\"8\":\"vuit\",\"9\":\"nou\",\"10\":\"deu\",\"11\":\"onze\",\"12\":\"dotze\",\"13\":\"tretze\",\"14\":\"catorze\",\"15\":\"quinze\",\"16\":\"setze\",\"17\" :\"disset\",\"18\":\"divuit\",\"19\":\"dinou\",\"20\" : \"vint\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=0\n",
    "fgdf['Numlist']=[[] for _ in range(len(fgdf))]\n",
    "fgdf['MIN DAYS']=''\n",
    "for fi,fr in fgdf.iterrows():\n",
    "    auto=\"\"\n",
    "    match2=set()\n",
    "    match1=set()\n",
    "    for i,r in fdf[(fdf['filetype']=='NOTIFICATION')&(fdf['filename'].isin(fr['files']))].iterrows():\n",
    "        s= r['text_response']\n",
    "        if len(s.strip())>0:\n",
    "            s='\\n'.join(list(filter(None,s.split('\\n')))).lower()\n",
    "\n",
    "            fgdf.loc[fi,'Court']=s.split('\\n')[0]\n",
    "            if 'procurador' in s.lower():\n",
    "                fgdf.loc[fi,'Solictor']=list(filter(None,s[s.lower().index('procurador')+10:].split('\\n')))[0]\n",
    "\n",
    "\n",
    "            ptype=\"\"\n",
    "\n",
    "            for x in procedures.values():\n",
    "\n",
    "                if x.lower() in ' '.join(s.split()):\n",
    "\n",
    "                    fgdf.loc[fi,'Procedure_Type']=x\n",
    "                    ptype=x\n",
    "                    break\n",
    "            if ptype!=\"\":\n",
    "                if fr['filegroup']=='INADMISION25':\n",
    "                            print ' YESSS'\n",
    "                if 'procedimiento' in s.lower():\n",
    "                    match=re.search(r'(\\d{1,20}/\\d{4})',s.split('procedimiento')[1])\n",
    "\n",
    "                else:\n",
    "                    s1=''.join(s.split())\n",
    "                    match1=set(re.findall(r'(\\d{1,20}/\\d{4})',s1))\n",
    "                    match2={'/'.join(x.split('/')[1:])for x in re.findall(r'(\\d{1,2}/\\d{1,2}/\\d{4})',s1)}\n",
    "\n",
    "            if not match is None :\n",
    "                    auto=match.group(0)\n",
    "            elif not (match1-match2) is None and len((match1-match2))>0 :\n",
    "                    auto=list(match1-match2)[0]\n",
    "    if(fr['group_predicted_class']=='N1')or(fr['group_predicted_class']=='N3')or(fr['group_predicted_class']=='N4'):\n",
    "        for ki,kr in extKeywords[(extKeywords['notification_type'].str.contains('AMOUNT'))&(extKeywords['fileclass']==fr['group_predicted_class'])].iterrows():\n",
    "            for i,r in fdf[(fdf['filename'].isin(fr['files']))&(fdf['filetype']==kr['filetype'])].iterrows():\n",
    "                text=''.join(r['text_response'].split())\n",
    "    #         \n",
    "                if r['text_response'][:5]!='Error':\n",
    "                    \n",
    "                    f=True\n",
    "                    t=text\n",
    "                    for k in kr['keyword']:\n",
    "                        k1=''.join(unidecode.unidecode(k).split()).lower()\n",
    "                        if  k1 in t:\n",
    "                            t=t[t.index(k1)+len(k1):]\n",
    "                        else:\n",
    "                            f=False\n",
    "                    k1=' '.join(kr['keyword'][0].split())    \n",
    "                    if f :\n",
    "                        tex=' '.join(r['text_response'].split())\n",
    "\n",
    "                        fgdf.loc[fi,'Amount']=tex[tex.index(k1)+len(k1):].split()[0]\n",
    "    if((fr['group_predicted_class']=='N9')or(fr['group_predicted_class']=='N10')):\n",
    "#         for ki,kr in extKeywords[(extKeywords['notification_type'].str.contains('TIME FRAME'))&(extKeywords['fileclass']==fr['group_predicted_class'])].iterrows():\n",
    "            for i,r in fdf[(fdf['filename'].isin(fr['files']))&(fdf['filetype']=='NOTIFICATION')].iterrows():\n",
    "                text=' '.join(unidecode.unidecode(r['text_response']).split())\n",
    "    #           \n",
    "                nls=[]\n",
    "                nlc=[]\n",
    "                if r['text_response'][:5]!='Error':\n",
    "                    \n",
    "                    f=True\n",
    "                    t=text\n",
    "                    \n",
    "                    k1='dias'\n",
    "                    \n",
    "                    if  k1 in t.lower():\n",
    "                          \n",
    "                        nls+=  [t.lower().split()[i-1] for i, x in enumerate(t.lower().split()) if 'dias' in x ]\n",
    "                    elif  'dies' in t.lower():\n",
    "                          \n",
    "                        nlc+=  [t.lower().split()[i-1] for i, x in enumerate(t.lower().split()) if 'dies' in x ]\n",
    "                    else:\n",
    "                            f=False\n",
    "                    k1=' '.join(kr['keyword'][0].split())    \n",
    "                    if f :\n",
    "                        min=100\n",
    "                        ls=[]\n",
    "                        if len(nls)>0:\n",
    "                            fgdf.at[fi,'Numlist']=nls\n",
    "                            ls=nls\n",
    "                            numbers=numspan\n",
    "                        elif len(nlc)>0:\n",
    "                            fgdf.at[fi,'Numlist']=nlc\n",
    "                            ls=nlc\n",
    "                            numbers=numcat\n",
    "                        for num in ls:\n",
    "                            if num in numbers.values():\n",
    "                                n=int([x for x in numbers.keys() if numbers[x]==num ][0])\n",
    "                                if n < min:\n",
    "                                    min=n\n",
    "                            elif num in numbers.keys():\n",
    "                                if int(num) < min:\n",
    "                                    min=int(num)\n",
    "                            else:\n",
    "                                print num\n",
    "                        if min!=100:\n",
    "                            fgdf.loc[fi,'MIN DAYS']=min\n",
    "                        \n",
    "    if (fr['group_predicted_class']=='N5')|(fr['group_predicted_class']=='N6')|(fr['group_predicted_class']=='N9'):\n",
    "        \n",
    "\n",
    "        for ki,kr in extKeywords[~(extKeywords['notification_type'].str.contains('TIME FRAME'))&(extKeywords['fileclass']==fr['group_predicted_class'])].iterrows():\n",
    "            for i,r in fdf[(fdf['filename'].isin(fr['files']))&(fdf['filetype']=='NOTIFICATION')].iterrows():\n",
    "                text=''.join(r['text_response'].split())\n",
    "    #         \n",
    "                if r['text_response'][:5]!='Error':\n",
    "                    \n",
    "                    f=True\n",
    "                    t=text\n",
    "                    for k in kr['keyword']:\n",
    "                        k1=''.join(unidecode.unidecode(k).split()).lower()\n",
    "                        if  k1 in t:\n",
    "                            t=t[t.index(k1)+len(k1):]\n",
    "                        else:\n",
    "                            f=False\n",
    "                    k1=' '.join(kr['keyword'][0].split())    \n",
    "                    if f :\n",
    "                        fgdf.loc[fi,fr['group_predicted_class']+'-Extraction']=[dict({kr['notification_type']:kr['keyword']})]\n",
    "                        if fr['group_predicted_class']=='N5':\n",
    "                            fgdf.loc[fi,'MIN DAYS']=5\n",
    "    for i,r in fdf[(fdf['filetype']=='TICKET')&(fdf['filename'].isin(fr['files']))].iterrows():\n",
    "        \n",
    "            if r.table_response[:5]!='Error':\n",
    "\n",
    "                js= json.loads(unidecode.unidecode( json.dumps(json.loads(r.table_response), ensure_ascii=False)))\n",
    "                table2=json.loads(js['table_2'])\n",
    "#                 print(r['filename'],js[\"table_1\"][[x for x in js[\"table_1\"].keys() if 'Fecha' in x][0]],table2['1'][[x for x in table2['1'].keys() if 'Fecha' in x][0]])\n",
    "                c+=1\n",
    "                fgdf.loc[fi,\"Document date\"]=js[\"table_1\"][[x for x in js[\"table_1\"].keys() if 'Fecha' in x][0]]\n",
    "                fgdf.loc[fi,\"Stamp date\"]=table2['1'][[x for x in table2['1'].keys() if 'Fecha' in x][0]]\n",
    "#                 print js\n",
    "                \n",
    "                \n",
    "                \n",
    "                fgdf.loc[fi,'Solictor']=js[\"table_1\"]['Destinatarios']['_value']\n",
    "                fgdf.loc[fi,'Court']=js[\"table_1\"]['Remitente'][[x for x in js[\"table_1\"]['Remitente'].keys() if str(x)[:6].lower()=='organo'][0]]\n",
    "                auto=\"\"\n",
    "                try:\n",
    "                    s=json.loads(unidecode.unidecode(r['table_response']))['table_1']['Datos del mensaje']['Procedimiento destino']\n",
    "\n",
    "                except Exception as e:\n",
    "                    s=str( json.loads(r['table_response'])['table_1']['Datos del mensaje'])\n",
    "        #             print str(e)\n",
    "                match1=set(re.findall(r'(\\d{1,20}/\\d{4})',s))\n",
    "                match2={'/'.join(x.split('/')[1:])for x in re.findall(r'(\\d{1,2}/\\d{1,2}/\\d{4})',s)}\n",
    "                \n",
    "                f=False\n",
    "                for x in procedures.keys():\n",
    "                    if x.lower() in  s.lower():\n",
    "                        f=True\n",
    "                        proced= procedures[x]\n",
    "                if f:\n",
    "                    fgdf.loc[fi,'Procedure_Type']=proced\n",
    "                if not (match1-match2) is None :\n",
    "                    auto=list(match1-match2)[0]\n",
    "                    \n",
    "\n",
    "    fgdf.loc[fi,'Auto']=auto\n",
    "            \n",
    "\n",
    "fgdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('/home/thrymr/File_Group_Result.xlsx')\n",
    "fgdf.to_excel(writer,'Sheet1')\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
