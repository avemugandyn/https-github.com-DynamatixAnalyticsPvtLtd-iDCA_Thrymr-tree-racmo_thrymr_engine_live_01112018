{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pdfquery\n",
    "import json\n",
    "from shapely.geometry import box\n",
    "from shapely.ops import cascaded_union\n",
    "import pdftableextract as pte\n",
    "from math import floor\n",
    "import pickle\n",
    "from pymongo import MongoClient\n",
    "from os import listdir\n",
    "from os.path import isfile, join, isdir\n",
    "from os import listdir\n",
    "import re\n",
    "import pickle\n",
    "import hashlib\n",
    "import unidecode\n",
    "from fuzzysearch import find_near_matches\n",
    "import textract\n",
    "import unicodedata\n",
    "import pydblite\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "KeywordDir=\"/home/thrymr/Racmo/Notification Keywords/\"\n",
    "keyword_files = [join(KeywordDir,f) for f in listdir(KeywordDir)\\\n",
    "                 if isfile(join(KeywordDir, f)) and \n",
    "                 f[-4:].lower() == \"xlsx\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorise Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls1, ls3, s1 = [], [], []\n",
    "for f in keyword_files:\n",
    "    xl_file = pd.ExcelFile(f)\n",
    "    dfs = xl_file.parse(xl_file.sheet_names[0])\n",
    "    tic=False\n",
    "    for index, row in dfs.iterrows():\n",
    "        ite=dict()\n",
    "        if(row[0]=='TICKETS' or row[0]=='TICKET'):\n",
    "            tic=True\n",
    "        if(row[0]!='TICKETS' and row[0]!='TICKET' and isinstance(row[0], basestring)):\n",
    "        \n",
    "            ite['file_class']=f.split('/')[-1].split()[0]\n",
    "            s1.append(ite['file_class'])\n",
    "            ite['notification_type']=row[0]\n",
    "            if(tic):\n",
    "                ite['file_type']='TICKET'\n",
    "            else:\n",
    "                ite['file_type']='NOTIFICATION'\n",
    "            kw=list()\n",
    "            for i in range(1,row.size):\n",
    "                if(isinstance(row[i], basestring) and row[i]!='+'):\n",
    "                    kw.append(unidecode.unidecode(row[i]).lower() )\n",
    "            ite['keyword']=kw\n",
    "            if(ite['file_class'] == 'NX'):\n",
    "                ls3.append(ite)\n",
    "            else:\n",
    "                ls1.append(ite)\n",
    "newkdf=pd.DataFrame(ls1)\n",
    "suspkdf=pd.DataFrame(ls3)\n",
    "suspkdf=suspkdf.rename(columns={\"notification_type\":\"remove_class\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfclass={ 'N1':'CLAIM ADMITTED TO PROCEDURE','N2':'ACCEPTED TRANSFER OF LEGAL REPRESENTATION',\n",
    "           'N3':'ENFORCEMENT ORDER','N4':'STATEMENT OF PAYMENT',\n",
    "           'N5':'REJECTED CLAIMS','N6':'REJECTED TRANSFER OF LEGAL REPRESENTATION',\n",
    "           'N7':'HEARING','N8':'ASSET INQUIRY','N9':'PLACE OF RESIDENCY REQUIRED',\n",
    "           'N10':'REQUIREMENT','N11':'BANK TRANSFERS','N12':'SOLICITOR REMOVAL',\n",
    "           'N13':'SUSPENDED HEARINGS','N14':'CANCELLED HEARINGS','N15':'NEGATIVE ASSET INQUIRY','N16':'PENDING ASSET INQUIRY'}\n",
    "\n",
    "newkdf['purpose']=''\n",
    "n=newkdf.iterrows()\n",
    "for i,row in n:\n",
    "    if(not ( row['file_class'] =='N5'or row['file_class'] =='N6')):\n",
    "        if(pdfclass[row['file_class']] in row['notification_type']):\n",
    "            newkdf.loc[i,'purpose']='CLASSIFICATION'\n",
    "        else:\n",
    "            newkdf.loc[i,'purpose']='EXTRACTION'\n",
    "    elif row['file_class'] =='N5':\n",
    "        if('N5 - REJECTED CLAIMS' in row['notification_type']):\n",
    "            newkdf.loc[i,'purpose']='CLASSIFICATION'\n",
    "        else:\n",
    "            newkdf.loc[i,'purpose']='EXTRACTION'\n",
    "    elif row['file_class'] =='N6':\n",
    "        if('N6 - REJECTED TRANSFER OF LEGAL REPRESENTATION' in row['notification_type']):\n",
    "            newkdf.loc[i,'purpose']='CLASSIFICATION'\n",
    "        else:\n",
    "            newkdf.loc[i,'purpose']='EXTRACTION'\n",
    "            \n",
    "k=newkdf[(newkdf['file_class']=='N10') & (newkdf['purpose']=='CLASSIFICATION')&(newkdf['file_type']=='NOTIFICATION')].groupby('notification_type')\n",
    "new10df=pd.DataFrame(columns=newkdf.columns)\n",
    "i=0\n",
    "for lidx in k.groups['N10 - REQUIREMENTS']:\n",
    "    for ridx in k.groups['N10 - REQUIREMENT SPECIFICATION']:\n",
    "        new10df=new10df.append(newkdf.iloc[lidx],ignore_index=True)\n",
    "        \n",
    "        new10df.loc[i,'keyword']=new10df.loc[i,'keyword']+newkdf.loc[ridx,'keyword']\n",
    "        i=i+1\n",
    "newkdf = newkdf[~((newkdf['file_class']=='N10') & (newkdf['purpose']=='CLASSIFICATION')&(newkdf['file_type']=='NOTIFICATION')&\n",
    "                  ((newkdf['notification_type']=='N10 - REQUIREMENTS')|(newkdf['notification_type']=='N10 - REQUIREMENT SPECIFICATION')))].append(new10df,ignore_index=True)\n",
    "newkdf = newkdf.rename(columns={'file_class':'fileclass','file_type':'filetype',\"notification_type\":\"decision_type\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore')\n",
    "kdf=newkdf\n",
    "kdf['keywordHash'] = kdf['keyword'].apply(lambda x :hashlib.sha256(json.dumps(x)).hexdigest())\n",
    "kdf['sub'] = kdf['keyword'].apply(lambda x :[])\n",
    "kdf['bias']=kdf['fileclass']\n",
    "kdf.loc[(kdf['fileclass']=='N2')&(kdf['filetype']=='NOTIFICATION'),'bias']='N12'\n",
    "def add_sub_link_keyword(kdf,keywords,fileclass,filetype,purpose,decision_type,bias,parent_class):\n",
    "    n_ind = kdf.index[-1]+1\n",
    "    for n15k in keywords:\n",
    "        k = [unidecode.unidecode(unicode(n15k,'UTF-8')).lower()]\n",
    "        hsh=hashlib.sha256(json.dumps(k)).hexdigest()\n",
    "        \n",
    "        if not hsh in kdf['keywordHash'].values.tolist():\n",
    "            kdf.set_value(n_ind,'fileclass',fileclass)\n",
    "            kdf.set_value(n_ind,'filetype',filetype)\n",
    "            kdf.set_value(n_ind,'purpose',purpose)\n",
    "            kdf.set_value(n_ind,'decision_type',decision_type)\n",
    "\n",
    "            kdf.set_value(n_ind,'keyword',k)\n",
    "            kdf.set_value(n_ind,'bias',bias)\n",
    "            kdf.set_value(n_ind,'keywordHash',hsh)\n",
    "            kdf.set_value(n_ind,'sub',[])\n",
    "        for i in kdf[(kdf['fileclass']==parent_class)&(kdf['filetype']=='NOTIFICATION')&(kdf['purpose']=='CLASSIFICATION')].index:\n",
    "            \n",
    "            kx = kdf[kdf.index==i]['sub'].values[0]\n",
    "            kx.append(hsh)\n",
    "            kdf.set_value\n",
    "            (i,'sub',kx)\n",
    "        n_ind+=1\n",
    "    return kdf\n",
    "N14_from_N13 = ['SE DECLARA TERMINADO','TENER POR TERMINADO','DESISTIMIENTO DEL PROCESO',\n",
    " 'SE DECRETA LA TERMINACION DEL PROCESO','HABIENDOSE SOLICITADO DESISTIMIENTO','HABER LLEGADO A UN ACUERDO']\n",
    "#Parent->N2,Notification,classification\n",
    "N2_solicitor_list=[\"MALAGON LOYO\",\"ALCOCER ANTON\",\"GARCIA ABASCAL\",\"GARCÍA ABASCAL\"]\n",
    "#Parent->N4,Notification,classification\n",
    "N6_from_N2=[\"NO HA LUGAR A TENER POR PERSONADA\",\"NO HA LUGAR A LO SOLICITADO\"]\n",
    "N2_from_N6=[\"EN ESTE CASO HABIÉNDOSE JUSTIFICADO DE MODO FEHACIENTE LA REALIDAD DE LA CESIÓN\"]\n",
    "N9_from_N10=[\"APORTE NOTA SIMPLE DEL REGISTRO MERCANTIL\",\"ES DESCONOCIDO EN ESTE DOMICILIO\"]\n",
    "N11_from_N4 = ['TRANSFERENCIA','EL No DE CUENTA DESIGNADO','A LA CUENTA BANCARIA DESIGNADA',\n",
    "                        'MEDIANTE TRANSFERENCIA A LA CUENTA DESIGNADA','MEDIANTE TRANSFERENCIA','SERA TRANSFERIDO']\n",
    "N3_from_N10 = ['NOTIFIQUESE ESTA RESOLUCION AL/LOS EJECUTADOS CON ENTREGA DE COPIA DE LA DEMANDA EJECUTIVA']\n",
    "#Parent->N16,Notification,classification\n",
    "N8_from_N16 = ['RESUMEN DEL RESULTADO']\n",
    "N10_from_N11=['REQUIÉRASE A LA PARTE EJECUTANTE A FIN DE QUE DESIGNE CUENTA BANCARIA']\n",
    "#Parent->N16,Notification,classification\n",
    "N15_from_N16 = ['CONSULTA INTEGRAL','RESUMEN DE INCIDENCIAS O INFORMACION NO ENCONTRADA']\n",
    "N5_to_N10=['BAJO APERCIBIMIENTO DE QUE DE NO VERIFICARSE','SE ACUERDA LA PRÓRROGA DEL PLAZO','SE PROCEDERÁ A LA INADMISIÓN A TRÁMITE']\n",
    "N4_from_N11=['CUENTA DE FONDOS PROVISIONALMENTE ABANDONADOS','MANDAMIENTO DE PAGO','MANDAMIENTO DE DEVOLUCIÓN','MANDAMIENTO TELEMÁTICO DE PAGO']\n",
    "N13_from_N14 = ['HABIÉNDOSE SOLICITADO POR LA PARTE DEMANDANTE EL DESISTIMIENTO DEL PROCESO', 'ACORDANDOSE LO QUE PROCEDA UNA VEZ TRASCURRA EL PLAZO']\n",
    "kdf = add_sub_link_keyword(kdf,N14_from_N13,'N14','NOTIFICATION','CLASSIFICATION_2','N14-CANCELLED HEARINGS','N14','N13')\n",
    "kdf = add_sub_link_keyword(kdf,N6_from_N2,'N6','NOTIFICATION','CLASSIFICATION_2','N6-REJECTED TRANSFER OF LEGAL REPRESENTATION','N6','N2')\n",
    "kdf = add_sub_link_keyword(kdf,N2_from_N6,'N2','NOTIFICATION','CLASSIFICATION_2','N2- TRANSFER OF LEGAL REPRESENTATION','N2','N6')\n",
    "kdf = add_sub_link_keyword(kdf,N9_from_N10,'N9','NOTIFICATION','CLASSIFICATION_2','N9- PLACE OF RESIDENCY REQUIRED','N9','N10')\n",
    "\n",
    "kdf = add_sub_link_keyword(kdf,N2_solicitor_list,'N2','NOTIFICATION','AUXILIARY','N2-SOLICITOR LIST','N2','N2')\n",
    "kdf = add_sub_link_keyword(kdf,N11_from_N4,'N11','NOTIFICATION','CLASSIFICATION_2','N11-BANK TRANSFERS','N11','N4')\n",
    "kdf = add_sub_link_keyword(kdf,N5_to_N10,'N10','NOTIFICATION','CLASSIFICATION_2','N10-REQUIREMENTS','N10','N5')\n",
    "kdf = add_sub_link_keyword(kdf,N4_from_N11,'N4','NOTIFICATION','CLASSIFICATION_2','N4-STATEMENT OF PAYMENT','N4','N11')\n",
    "kdf = add_sub_link_keyword(kdf,N10_from_N11,'N10','NOTIFICATION','CLASSIFICATION_2','N10-REQUIREMENTS','N10','N11')\n",
    "kdf = add_sub_link_keyword(kdf, N3_from_N10, 'N3', 'NOTIFICATION', 'CLASSIFICATION_2', 'N3 EXTRACTION', 'N3', 'N10')\n",
    "kdf = add_sub_link_keyword(kdf, N13_from_N14, 'N13', 'NOTIFICATION', 'CLASSIFICATION_2', 'N13 EXTRACTION', 'N13', 'N14')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maintain Classification Hierarchy  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k1 in N6_from_N2:\n",
    "    k = [unidecode.unidecode(unicode(k1,'UTF-8')).lower()]\n",
    "    hsh=hashlib.sha256(json.dumps(k)).hexdigest()\n",
    "    for i in kdf[(kdf['fileclass']=='N2')&(kdf['purpose']=='AUXILIARY')].index:\n",
    "            kx = kdf[kdf.index==i]['sub'].values[0]\n",
    "            kx.append(hsh)\n",
    "            kdf.set_value(i,'sub ',kx)\n",
    "\n",
    "keys = [[unidecode.unidecode(unicode('RESUMEN DEL RESULTADO','UTF-8')).lower()],\n",
    "        [unidecode.unidecode(unicode('CONSULTA DE SITUACIONES LABORALES DE LA TGSS','UTF-8')).lower()\n",
    "         ,unidecode.unidecode(unicode('SITUACION ACTUAL: ALTA','UTF-8')).lower()]]\n",
    "for k in keys:\n",
    "    hsh8=hashlib.sha256(json.dumps(k)).hexdigest()\n",
    "    n_ind = kdf.index[-1]+1\n",
    "    if not hsh8 in kdf['keywordHash'].values.tolist():\n",
    "        kdf.set_value(n_ind,'fileclass','N8')\n",
    "        kdf.set_value(n_ind,'filetype','NOTIFICATION')\n",
    "        kdf.set_value(n_ind,'purpose','CLASSIFICATION')\n",
    "        kdf.set_value(n_ind,'decision_type','N8-ASSET INQUIRY')\n",
    "\n",
    "        kdf.set_value(n_ind,'keyword',k)\n",
    "        kdf.set_value(n_ind,'bias','N8')\n",
    "        kdf.set_value(n_ind,'keywordHash',hsh8)\n",
    "        kdf.set_value(n_ind,'sub',[])\n",
    "    for i in kdf[(kdf['fileclass']=='N16')&(kdf['purpose']=='CLASSIFICATION')].index:\n",
    "\n",
    "        kx = kdf[kdf.index==i]['sub'].values[0]\n",
    "        kx.append(hsh8)\n",
    "        kdf.set_value(i,'sub',kx)\n",
    "keys = [[unidecode.unidecode(unicode('CONSULTA INTEGRAL','UTF-8')).lower(),unidecode.unidecode(unicode('RESUMEN DE INCIDENCIAS O INFORMACION NO ENCONTRADA','UTF-8')).lower()],[unidecode.unidecode(unicode('CONSULTA DE SITUACIONES LABORALES DE LA TGSS','UTF-8')).lower(),unidecode.unidecode(unicode('SITUACION ACTUAL: BAJA','UTF-8')).lower()]]\n",
    "for k in keys:\n",
    "    hsh=hashlib.sha256(json.dumps(k)).hexdigest()\n",
    "    n_ind = kdf.index[-1]+1\n",
    "    if not hsh in kdf['keywordHash'].values.tolist():\n",
    "        kdf.set_value(n_ind,'fileclass','N15')\n",
    "        kdf.set_value(n_ind,'filetype','NOTIFICATION')\n",
    "        kdf.set_value(n_ind,'purpose','CLASSIFICATION_2')\n",
    "        kdf.set_value(n_ind,'decision_type','N15-NEGATIVE ASSET INQUIRY')\n",
    "\n",
    "        kdf.set_value(n_ind,'keyword',k)\n",
    "        kdf.set_value(n_ind,'bias','N15')\n",
    "        kdf.set_value(n_ind,'keywordHash',hsh)\n",
    "        kdf.set_value(n_ind,'sub',[hsh8])\n",
    "    for i in kdf[(kdf['fileclass']=='N16')&(kdf['filetype']=='NOTIFICATION')&(kdf['purpose']=='CLASSIFICATION')].index:\n",
    "\n",
    "        kx = kdf[kdf.index==i]['sub'].values[0]\n",
    "        kx.append(hsh8)\n",
    "        kdf.set_value(i,'sub',kx)\n",
    "for hsh in kdf[(kdf['fileclass']=='N13')&(kdf['filetype']=='NOTIFICATION')]['keywordHash'].values.tolist():\n",
    "    for i in kdf[(kdf['fileclass']=='N7')&(kdf['filetype']=='NOTIFICATION')&(kdf['purpose']=='CLASSIFICATION')].index:\n",
    "\n",
    "        kx = kdf[kdf.index==i]['sub'].values[0]\n",
    "        kx.append(hsh)\n",
    "        kdf.set_value(i,'sub',kx) \n",
    "for hs in kdf[(kdf['fileclass']=='N5')&(kdf['filetype']=='NOTIFICATION')&(kdf['purpose']=='CLASSIFICATION')]['keywordHash'].values.tolist():\n",
    "    for i in kdf[(kdf['fileclass']=='N1')&(kdf['filetype']=='NOTIFICATION')&(kdf['purpose']=='CLASSIFICATION')].index:\n",
    "\n",
    "        kx = kdf[kdf.index==i]['sub'].values[0]\n",
    "        kx.append(hs)\n",
    "        kdf.set_value(i,'sub',kx) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83, 16, 545, 81, 82, 572, 543, 542, 583, 567, 563, 397, 445, 544, 541]\n"
     ]
    }
   ],
   "source": [
    "kdf['keyword'] = kdf['keyword'].apply(lambda x : json.dumps(x))\n",
    "kg=kdf[kdf['purpose']=='CLASSIFICATION'].groupby('keyword')\n",
    "ls=[]\n",
    "for k,v in kg.groups.items():\n",
    "    if(len(v)>1):\n",
    "        if len(set(kdf[kdf['keyword']==k]['fileclass'].values)) ==1:\n",
    "            ls=ls+v.values.tolist()[1:]\n",
    "        else:\n",
    "            if set(kdf[kdf['keyword']==k]['fileclass'].values)<=set(['N8','N15','N16']):\n",
    "                for j in v.values.tolist():\n",
    "                    if kdf.loc[j,'fileclass']!='N16':\n",
    "                        ls.append(j)\n",
    "            elif set(kdf[kdf['keyword']==k]['fileclass'].values)<=set(['N13','N14']):\n",
    "                for j in v.values.tolist():\n",
    "                    if kdf.loc[j,'fileclass']!='N13':\n",
    "                        ls.append(j)\n",
    "print(ls)\n",
    "kdf['keyword'] = kdf['keyword'].apply(lambda x : json.loads(x))\n",
    "\n",
    "kdf=kdf.drop(kdf.index[ls])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'keywords':kdf,\n",
    "     'susKeyword':suspkdf\n",
    "    }\n",
    "with open('Keyword.pickle', 'wb') as handle:\n",
    "    pickle.dump(a, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# with open('Keyword_Analysis.pickle', 'wb') as handle:\n",
    "#     pickle.dump(a, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2165, 9), (103, 4))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kdf.shape, suspkdf.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
